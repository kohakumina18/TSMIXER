{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#mount ggdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZqkPvgky-ew",
        "outputId": "30113e82-5459-4d70-e178-259c7a5059ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import and install tsmixer\n",
        "!git clone https://github.com/ditschuk/pytorch-tsmixer.git\n",
        "%cd pytorch-tsmixer\n",
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr8J6a84zvF3",
        "outputId": "eedf6a0d-b9fa-499e-d229-edb238196aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-tsmixer'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 48 (delta 21), reused 41 (delta 15), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (48/48), 19.28 KiB | 9.64 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "/content/pytorch-tsmixer\n",
            "Processing /content/pytorch-tsmixer\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>1.6 in /usr/local/lib/python3.10/dist-packages (from pytorch-tsmixer==0.2.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>1.6->pytorch-tsmixer==0.2.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>1.6->pytorch-tsmixer==0.2.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>1.6->pytorch-tsmixer==0.2.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>1.6->pytorch-tsmixer==0.2.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>1.6->pytorch-tsmixer==0.2.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>1.6->pytorch-tsmixer==0.2.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>1.6->pytorch-tsmixer==0.2.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>1.6->pytorch-tsmixer==0.2.0) (3.0.2)\n",
            "Building wheels for collected packages: pytorch-tsmixer\n",
            "  Building wheel for pytorch-tsmixer (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-tsmixer: filename=pytorch_tsmixer-0.2.0-py3-none-any.whl size=10459 sha256=87e4c793e2649224a128ec97747bbc9b63d0621afd14d38972edfdaecf7bf51b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/38/42/4625f0ddcd50bd1cd731dfccafc17cf645768f433105317169\n",
            "Successfully built pytorch-tsmixer\n",
            "Installing collected packages: pytorch-tsmixer\n",
            "Successfully installed pytorch-tsmixer-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/local/lib/python3.10/dist-packages/torchtsmixer\n",
        "\n",
        "!cat /usr/local/lib/python3.10/dist-packages/torchtsmixer/layers.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpa9rdwXMQO1",
        "outputId": "fbda0225-994b-451c-cc5f-13311d2f6eef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__init__.py  layers.py\t__pycache__  tsmixer_ext.py  tsmixer.py\n",
            "from __future__ import annotations\n",
            "\n",
            "from collections.abc import Callable\n",
            "\n",
            "import torch\n",
            "import torch.nn.functional as F\n",
            "from torch import Tensor, nn\n",
            "\n",
            "\n",
            "class TimeBatchNorm2d(nn.BatchNorm1d):\n",
            "    \"\"\"A batch normalization layer that normalizes over the last two dimensions of a\n",
            "    sequence in PyTorch, mimicking Keras behavior.\n",
            "\n",
            "    This class extends nn.BatchNorm1d to apply batch normalization across time and\n",
            "    feature dimensions.\n",
            "\n",
            "    Attributes:\n",
            "        num_time_steps (int): Number of time steps in the input.\n",
            "        num_channels (int): Number of channels in the input.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self, normalized_shape: tuple[int, int]):\n",
            "        \"\"\"Initializes the TimeBatchNorm2d module.\n",
            "\n",
            "        Args:\n",
            "            normalized_shape (tuple[int, int]): A tuple (num_time_steps, num_channels)\n",
            "                representing the shape of the time and feature dimensions to normalize.\n",
            "        \"\"\"\n",
            "        num_time_steps, num_channels = normalized_shape\n",
            "        super().__init__(num_channels * num_time_steps)\n",
            "        self.num_time_steps = num_time_steps\n",
            "        self.num_channels = num_channels\n",
            "\n",
            "    def forward(self, x: Tensor) -> Tensor:\n",
            "        \"\"\"Applies the batch normalization over the last two dimensions of the input tensor.\n",
            "\n",
            "        Args:\n",
            "            x (Tensor): A 3D tensor with shape (N, S, C), where N is the batch size,\n",
            "                S is the number of time steps, and C is the number of channels.\n",
            "\n",
            "        Returns:\n",
            "            Tensor: A 3D tensor with batch normalization applied over the last two dims.\n",
            "\n",
            "        Raises:\n",
            "            ValueError: If the input tensor is not 3D.\n",
            "        \"\"\"\n",
            "        if x.ndim != 3:\n",
            "            raise ValueError(f\"Expected 3D input tensor, but got {x.ndim}D tensor instead.\")\n",
            "\n",
            "        # Reshaping input to combine time and feature dimensions for normalization\n",
            "        x = x.reshape(x.shape[0], -1, 1)\n",
            "\n",
            "        # Applying batch normalization\n",
            "        x = super().forward(x)\n",
            "\n",
            "        # Reshaping back to original dimensions (N, S, C)\n",
            "        x = x.reshape(x.shape[0], self.num_time_steps, self.num_channels)\n",
            "\n",
            "        return x\n",
            "\n",
            "\n",
            "class FeatureMixing(nn.Module):\n",
            "    \"\"\"A module for feature mixing with flexibility in normalization and activation.\n",
            "\n",
            "    This module provides options for batch normalization before or after mixing features,\n",
            "    uses dropout for regularization, and allows for different activation functions.\n",
            "\n",
            "    Args:\n",
            "        sequence_length: The length of the sequences to be transformed.\n",
            "        input_channels: The number of input channels to the module.\n",
            "        output_channels: The number of output channels from the module.\n",
            "        ff_dim: The dimension of the feed-forward network internal to the module.\n",
            "        activation_fn: The activation function used within the feed-forward network.\n",
            "        dropout_rate: The dropout probability used for regularization.\n",
            "        normalize_before: A boolean indicating whether to apply normalization before\n",
            "            the rest of the operations.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(\n",
            "        self,\n",
            "        sequence_length: int,\n",
            "        input_channels: int,\n",
            "        output_channels: int,\n",
            "        ff_dim: int,\n",
            "        activation_fn: Callable[[torch.Tensor], torch.Tensor] = F.relu,\n",
            "        dropout_rate: float = 0.1,\n",
            "        normalize_before: bool = True,\n",
            "        norm_type: type[nn.Module] = TimeBatchNorm2d,\n",
            "    ):\n",
            "        \"\"\"Initializes the FeatureMixing module with the provided parameters.\"\"\"\n",
            "        super().__init__()\n",
            "\n",
            "        self.norm_before = (\n",
            "            norm_type((sequence_length, input_channels))\n",
            "            if normalize_before\n",
            "            else nn.Identity()\n",
            "        )\n",
            "        self.norm_after = (\n",
            "            norm_type((sequence_length, output_channels))\n",
            "            if not normalize_before\n",
            "            else nn.Identity()\n",
            "        )\n",
            "\n",
            "        self.activation_fn = activation_fn\n",
            "        self.dropout = nn.Dropout(dropout_rate)\n",
            "        self.fc1 = nn.Linear(input_channels, ff_dim)\n",
            "        self.fc2 = nn.Linear(ff_dim, output_channels)\n",
            "\n",
            "        self.projection = (\n",
            "            nn.Linear(input_channels, output_channels)\n",
            "            if input_channels != output_channels\n",
            "            else nn.Identity()\n",
            "        )\n",
            "\n",
            "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
            "        \"\"\"Forward pass for the FeatureMixing module.\n",
            "\n",
            "        Args:\n",
            "            x: A 3D tensor with shape (N, C, L) where C is the channel dimension.\n",
            "\n",
            "        Returns:\n",
            "            The output tensor after feature mixing.\n",
            "        \"\"\"\n",
            "        x_proj = self.projection(x)\n",
            "\n",
            "        x = self.norm_before(x)\n",
            "\n",
            "        x = self.fc1(x)  # Apply the first linear transformation.\n",
            "        x = self.activation_fn(x)  # Apply the activation function.\n",
            "        x = self.dropout(x)  # Apply dropout for regularization.\n",
            "        x = self.fc2(x)  # Apply the second linear transformation.\n",
            "        x = self.dropout(x)  # Apply dropout again if needed.\n",
            "\n",
            "        x = x_proj + x  # Add the projection shortcut to the transformed features.\n",
            "\n",
            "        return self.norm_after(x)\n",
            "\n",
            "\n",
            "class ConditionalFeatureMixing(nn.Module):\n",
            "    \"\"\"Conditional feature mixing module that incorporates static features.\n",
            "\n",
            "    This module extends the feature mixing process by including static features. It uses\n",
            "    a linear transformation to integrate static features into the dynamic feature space,\n",
            "    then applies the feature mixing on the concatenated features.\n",
            "\n",
            "    Args:\n",
            "        input_channels: The number of input channels of the dynamic features.\n",
            "        output_channels: The number of output channels after feature mixing.\n",
            "        static_channels: The number of channels in the static feature input.\n",
            "        ff_dim: The inner dimension of the feedforward network used in feature mixing.\n",
            "        activation_fn: The activation function used in feature mixing.\n",
            "        dropout_rate: The dropout probability used in the feature mixing operation.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(\n",
            "        self,\n",
            "        sequence_length: int,\n",
            "        input_channels: int,\n",
            "        output_channels: int,\n",
            "        static_channels: int,\n",
            "        ff_dim: int,\n",
            "        activation_fn: Callable = F.relu,\n",
            "        dropout_rate: float = 0.1,\n",
            "        normalize_before: bool = False,\n",
            "        norm_type: type[nn.Module] = nn.LayerNorm,\n",
            "    ):\n",
            "        super().__init__()\n",
            "\n",
            "        self.fr_static = nn.Linear(static_channels, output_channels)\n",
            "        self.fm = FeatureMixing(\n",
            "            sequence_length,\n",
            "            input_channels + output_channels,\n",
            "            output_channels,\n",
            "            ff_dim,\n",
            "            activation_fn,\n",
            "            dropout_rate,\n",
            "            normalize_before=normalize_before,\n",
            "            norm_type=norm_type,\n",
            "        )\n",
            "\n",
            "    def forward(\n",
            "        self, x: torch.Tensor, x_static: torch.Tensor\n",
            "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
            "        \"\"\"Applies conditional feature mixing using both dynamic and static inputs.\n",
            "\n",
            "        Args:\n",
            "            x: A tensor representing dynamic features, typically with shape\n",
            "               [batch_size, time_steps, input_channels].\n",
            "            x_static: A tensor representing static features, typically with shape\n",
            "               [batch_size, static_channels].\n",
            "\n",
            "        Returns:\n",
            "            A tuple containing:\n",
            "            - The output tensor after applying conditional feature mixing.\n",
            "            - The transformed static features tensor for monitoring or further processing.\n",
            "        \"\"\"\n",
            "        v = self.fr_static(x_static)  # Transform static features to match output channels.\n",
            "        v = v.unsqueeze(1).repeat(\n",
            "            1, x.shape[1], 1\n",
            "        )  # Repeat static features across time steps.\n",
            "\n",
            "        return (\n",
            "            self.fm(\n",
            "                torch.cat([x, v], dim=-1)\n",
            "            ),  # Apply feature mixing on concatenated features.\n",
            "            v.detach(),  # Return detached static feature for monitoring or further use.\n",
            "        )\n",
            "\n",
            "\n",
            "class TimeMixing(nn.Module):\n",
            "    \"\"\"Applies a transformation over the time dimension of a sequence.\n",
            "\n",
            "    This module applies a linear transformation followed by an activation function\n",
            "    and dropout over the sequence length of the input feature tensor after converting\n",
            "    feature maps to the time dimension and then back.\n",
            "\n",
            "    Args:\n",
            "        input_channels: The number of input channels to the module.\n",
            "        sequence_length: The length of the sequences to be transformed.\n",
            "        activation_fn: The activation function to be used after the linear transformation.\n",
            "        dropout_rate: The dropout probability to be used after the activation function.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(\n",
            "        self,\n",
            "        sequence_length: int,\n",
            "        input_channels: int,\n",
            "        activation_fn: Callable = F.relu,\n",
            "        dropout_rate: float = 0.1,\n",
            "        norm_type: type[nn.Module] = TimeBatchNorm2d,\n",
            "    ):\n",
            "        \"\"\"Initializes the TimeMixing module with the specified parameters.\"\"\"\n",
            "        super().__init__()\n",
            "        self.norm = norm_type((sequence_length, input_channels))\n",
            "        self.activation_fn = activation_fn\n",
            "        self.dropout = nn.Dropout(dropout_rate)\n",
            "        self.fc1 = nn.Linear(sequence_length, sequence_length)\n",
            "\n",
            "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
            "        \"\"\"Applies the time mixing operations on the input tensor.\n",
            "\n",
            "        Args:\n",
            "            x: A 3D tensor with shape (N, C, L), where C = channel dimension and\n",
            "                L = sequence length.\n",
            "\n",
            "        Returns:\n",
            "            The normalized output tensor after time mixing transformations.\n",
            "        \"\"\"\n",
            "        x_temp = feature_to_time(\n",
            "            x\n",
            "        )  # Convert feature maps to time dimension. Assumes definition elsewhere.\n",
            "        x_temp = self.activation_fn(self.fc1(x_temp))\n",
            "        x_temp = self.dropout(x_temp)\n",
            "        x_res = time_to_feature(x_temp)  # Convert back from time to feature maps.\n",
            "\n",
            "        return self.norm(x + x_res)  # Apply normalization and combine with original input.\n",
            "\n",
            "\n",
            "class MixerLayer(nn.Module):\n",
            "    \"\"\"A residual block that combines time and feature mixing for sequence data.\n",
            "\n",
            "    This module sequentially applies time mixing and feature mixing, which are forms\n",
            "    of data augmentation and feature transformation that can help in learning temporal\n",
            "    dependencies and feature interactions respectively.\n",
            "\n",
            "    Args:\n",
            "        sequence_length: The length of the input sequences.\n",
            "        input_channels: The number of input channels to the module.\n",
            "        output_channels: The number of output channels from the module.\n",
            "        ff_dim: The inner dimension of the feedforward network used in feature mixing.\n",
            "        activation_fn: The activation function used in both time and feature mixing.\n",
            "        dropout_rate: The dropout probability used in both mixing operations.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(\n",
            "        self,\n",
            "        sequence_length: int,\n",
            "        input_channels: int,\n",
            "        output_channels: int,\n",
            "        ff_dim: int,\n",
            "        activation_fn: Callable = F.relu,\n",
            "        dropout_rate: float = 0.1,\n",
            "        normalize_before: bool = False,\n",
            "        norm_type: type[nn.Module] = nn.LayerNorm,\n",
            "    ):\n",
            "        \"\"\"Initializes the MixLayer with time and feature mixing modules.\"\"\"\n",
            "        super().__init__()\n",
            "\n",
            "        self.time_mixing = TimeMixing(\n",
            "            sequence_length,\n",
            "            input_channels,\n",
            "            activation_fn,\n",
            "            dropout_rate,\n",
            "            norm_type=norm_type,\n",
            "        )\n",
            "        self.feature_mixing = FeatureMixing(\n",
            "            sequence_length,\n",
            "            input_channels,\n",
            "            output_channels,\n",
            "            ff_dim,\n",
            "            activation_fn,\n",
            "            dropout_rate,\n",
            "            norm_type=norm_type,\n",
            "            normalize_before=normalize_before,\n",
            "        )\n",
            "\n",
            "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
            "        \"\"\"Forward pass for the MixLayer module.\n",
            "\n",
            "        Args:\n",
            "            x: A 3D tensor with shape (N, C, L) to be processed by the mixing layers.\n",
            "\n",
            "        Returns:\n",
            "            The output tensor after applying time and feature mixing operations.\n",
            "        \"\"\"\n",
            "        x = self.time_mixing(x)  # Apply time mixing first.\n",
            "        x = self.feature_mixing(x)  # Then apply feature mixing.\n",
            "\n",
            "        return x\n",
            "\n",
            "\n",
            "class ConditionalMixerLayer(nn.Module):\n",
            "    \"\"\"Conditional mix layer combining time and feature mixing with static context.\n",
            "\n",
            "    This module combines time mixing and conditional feature mixing, where the latter\n",
            "    is influenced by static features. This allows the module to learn representations\n",
            "    that are influenced by both dynamic and static features.\n",
            "\n",
            "    Args:\n",
            "        sequence_length: The length of the input sequences.\n",
            "        input_channels: The number of input channels of the dynamic features.\n",
            "        output_channels: The number of output channels after feature mixing.\n",
            "        static_channels: The number of channels in the static feature input.\n",
            "        ff_dim: The inner dimension of the feedforward network used in feature mixing.\n",
            "        activation_fn: The activation function used in both mixing operations.\n",
            "        dropout_rate: The dropout probability used in both mixing operations.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(\n",
            "        self,\n",
            "        sequence_length: int,\n",
            "        input_channels: int,\n",
            "        output_channels: int,\n",
            "        static_channels: int,\n",
            "        ff_dim: int,\n",
            "        activation_fn: Callable = F.relu,\n",
            "        dropout_rate: float = 0.1,\n",
            "        normalize_before: bool = False,\n",
            "        norm_type: type[nn.Module] = nn.LayerNorm,\n",
            "    ):\n",
            "        super().__init__()\n",
            "\n",
            "        self.time_mixing = TimeMixing(\n",
            "            sequence_length,\n",
            "            input_channels,\n",
            "            activation_fn,\n",
            "            dropout_rate,\n",
            "            norm_type=norm_type,\n",
            "        )\n",
            "        self.feature_mixing = ConditionalFeatureMixing(\n",
            "            sequence_length,\n",
            "            input_channels,\n",
            "            output_channels=output_channels,\n",
            "            static_channels=static_channels,\n",
            "            ff_dim=ff_dim,\n",
            "            activation_fn=activation_fn,\n",
            "            dropout_rate=dropout_rate,\n",
            "            normalize_before=normalize_before,\n",
            "            norm_type=norm_type,\n",
            "        )\n",
            "\n",
            "    def forward(self, x: torch.Tensor, x_static: torch.Tensor) -> torch.Tensor:\n",
            "        \"\"\"Forward pass for the conditional mix layer.\n",
            "\n",
            "        Args:\n",
            "            x: A tensor representing dynamic features, typically with shape\n",
            "               [batch_size, time_steps, input_channels].\n",
            "            x_static: A tensor representing static features, typically with shape\n",
            "               [batch_size, static_channels].\n",
            "\n",
            "        Returns:\n",
            "            The output tensor after applying time and conditional feature mixing.\n",
            "        \"\"\"\n",
            "        x = self.time_mixing(x)  # Apply time mixing first.\n",
            "        x, _ = self.feature_mixing(x, x_static)  # Then apply conditional feature mixing.\n",
            "\n",
            "        return x\n",
            "\n",
            "\n",
            "def time_to_feature(x: torch.Tensor) -> torch.Tensor:\n",
            "    \"\"\"Converts a time series tensor to a feature tensor.\"\"\"\n",
            "    return x.permute(0, 2, 1)\n",
            "\n",
            "\n",
            "feature_to_time = time_to_feature\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modding the model so it can process the longterm forecast and support debuggin\n",
        "%%writefile /usr/local/lib/python3.10/dist-packages/torchtsmixer/layers.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import Callable\n",
        "\n",
        "class TSMixerExt(nn.Module):\n",
        "    def __init__(self, sequence_length: int, input_channels: int, output_channels: int, static_channels: int, ff_dim: int, activation_fn: Callable = F.relu, dropout_rate: float = 0.1, normalize_before: bool = False, norm_type: type[nn.Module] = nn.LayerNorm):\n",
        "        super(TSMixerExt, self).__init__()\n",
        "        self.sequence_length = sequence_length\n",
        "        self.prediction_length = sequence_length  # Updated to match sequence_length\n",
        "        self.input_channels = input_channels\n",
        "        self.extra_channels = static_channels  # Updated to match static_channels\n",
        "        self.hidden_channels = ff_dim  # Updated to match ff_dim\n",
        "        self.static_channels = static_channels\n",
        "        self.output_channels = output_channels\n",
        "\n",
        "        # Define layers\n",
        "        self.fr_static = nn.Linear(static_channels, ff_dim)  # Updated to use ff_dim\n",
        "        self.fm = nn.Linear(input_channels + ff_dim + static_channels, output_channels)  # Updated to use ff_dim\n",
        "\n",
        "    def forward(self, x: torch.Tensor, x_static: torch.Tensor, x_extra_hist: torch.Tensor, x_extra_future: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass for the conditional mix layer.\n",
        "\n",
        "        Args:\n",
        "            x: A tensor representing dynamic features, typically with shape\n",
        "               [batch_size, time_steps, input_channels].\n",
        "            x_static: A tensor representing static features, typically with shape\n",
        "               [batch_size, static_channels].\n",
        "            x_extra_hist: A tensor representing extra historical features.\n",
        "            x_extra_future: A tensor representing extra future features.\n",
        "\n",
        "        Returns:\n",
        "            The output tensor after applying time and conditional feature mixing.\n",
        "        \"\"\"\n",
        "        print(f\"Inside forward, x shape: {x.shape}\")  # Debug: Print shape of x\n",
        "        print(f\"Inside forward, x_static shape: {x_static.shape}\")  # Debug: Print shape of x_static\n",
        "\n",
        "        x = self.time_mixing(x)  # Apply time mixing first\n",
        "        print(f\"Shape after time_mixing: {x.shape}\")  # Debug: Shape after time_mixing\n",
        "\n",
        "        x, _ = self.feature_mixing(x, x_static)  # Apply conditional feature mixing\n",
        "        print(f\"Shape after feature_mixing: {x.shape}\")  # Debug: Shape after feature mixing\n",
        "\n",
        "        return x\n",
        "\n",
        "def time_to_feature(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Converts a time series tensor to a feature tensor.\"\"\"\n",
        "    return x.permute(0, 2, 1)\n",
        "\n",
        "feature_to_time = time_to_feature\n",
        "\n",
        "# Dummy classes for TimeMixing and ConditionalFeatureMixing (for context)\n",
        "class TimeMixing(nn.Module):\n",
        "    def __init__(self, sequence_length, input_channels, activation_fn, dropout_rate, norm_type):\n",
        "        super(TimeMixing, self).__init__()\n",
        "        # Dummy layer\n",
        "        self.layer = nn.Linear(sequence_length, input_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.layer(x))\n",
        "\n",
        "class ConditionalFeatureMixing(nn.Module):\n",
        "    def __init__(self, sequence_length, input_channels, output_channels, static_channels, ff_dim, activation_fn, dropout_rate, normalize_before, norm_type):\n",
        "        super(ConditionalFeatureMixing, self).__init__()\n",
        "        # Dummy layers\n",
        "        self.layer = nn.Linear(input_channels + static_channels, ff_dim)\n",
        "        self.output_layer = nn.Linear(ff_dim, output_channels)\n",
        "\n",
        "    def forward(self, x, x_static):\n",
        "        v = F.relu(self.layer(torch.cat([x, x_static.unsqueeze(1).expand(-1, x.shape[1], -1)], dim=-1)))\n",
        "        return self.output_layer(v), v\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_gsPZnnNLfm",
        "outputId": "cabcb01e-0207-40c4-f824-2fabc4fecf1d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /usr/local/lib/python3.10/dist-packages/torchtsmixer/layers.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "E8vMIEs-w4-d"
      },
      "outputs": [],
      "source": [
        "#import thu vien\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchtsmixer import TSMixerExt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##short_term forecasting: 5 values\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load and preprocess electricity data\n",
        "def load_electricity_data():\n",
        "    data_path = '/content/drive/My Drive/Colab Notebooks/dataset/electricity/electricity.csv'\n",
        "    df = pd.read_csv(data_path)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df.set_index('date', inplace=True)\n",
        "    return df\n",
        "\n",
        "# Undersample data\n",
        "def undersample_data(df, fraction=0.1):\n",
        "    return df.sample(frac=fraction)\n",
        "\n",
        "# Normalize data\n",
        "def normalize_data(df):\n",
        "    scaler = MinMaxScaler()\n",
        "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
        "    return df, scaler\n",
        "\n",
        "# Prepare input features\n",
        "def prepare_data(df, sequence_length=10, prediction_length=5):\n",
        "    values = df.values.astype(float)\n",
        "    x_hist, y_target = [], []\n",
        "\n",
        "    for i in range(len(values) - sequence_length - prediction_length):\n",
        "        x_hist.append(values[i:i + sequence_length])\n",
        "        y_target.append(values[i + sequence_length:i + sequence_length + prediction_length])\n",
        "\n",
        "    x_hist = np.array(x_hist, dtype=np.float32).reshape(-1, sequence_length, 1)\n",
        "    y_target = np.array(y_target, dtype=np.float32).reshape(-1, prediction_length, 1)\n",
        "\n",
        "    x_hist = torch.tensor(x_hist, dtype=torch.float32)\n",
        "    y_target = torch.tensor(y_target, dtype=torch.float32)\n",
        "\n",
        "    dataset = TensorDataset(x_hist, y_target)\n",
        "    return dataset\n",
        "\n",
        "# Define a simple model architecture\n",
        "class ForecastModel(nn.Module):\n",
        "    def __init__(self, sequence_length, prediction_length):\n",
        "        super(ForecastModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=1, hidden_size=32, num_layers=2, batch_first=True)\n",
        "        self.fc = nn.Linear(32, prediction_length)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "def main():\n",
        "    drive.mount('/content/drive')\n",
        "    # Load and preprocess data\n",
        "    df = load_electricity_data()\n",
        "    df = undersample_data(df, fraction=0.1)\n",
        "    df, scaler = normalize_data(df)\n",
        "\n",
        "    sequence_length = 10\n",
        "    prediction_length = 5\n",
        "    batch_size = 128\n",
        "\n",
        "    dataset = prepare_data(df, sequence_length, prediction_length)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize model, loss, and optimizer\n",
        "    model = ForecastModel(sequence_length=sequence_length, prediction_length=prediction_length).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training\n",
        "    num_epochs = 100\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for x_hist_batch, y_target_batch in data_loader:\n",
        "            x_hist_batch, y_target_batch = x_hist_batch.to(device), y_target_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(x_hist_batch)\n",
        "            loss = criterion(predictions, y_target_batch.squeeze(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Validation - Predict the first 5 values for demonstration\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x_hist_batch, y_target_batch in data_loader:\n",
        "            x_hist_batch = x_hist_batch.to(device)\n",
        "            predictions = model(x_hist_batch)\n",
        "            print(\"Predictions:\", predictions.cpu().numpy()[:5])\n",
        "            print(\"Actual Values:\", y_target_batch.cpu().numpy()[:5])\n",
        "            break  # Print only the first batch\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gVeYWbzziSp",
        "outputId": "354e4fdc-6be1-48b0-d347-4b28252f2429"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch [1/100], Loss: 0.0377\n",
            "Epoch [2/100], Loss: 0.0414\n",
            "Epoch [3/100], Loss: 0.0361\n",
            "Epoch [4/100], Loss: 0.0423\n",
            "Epoch [5/100], Loss: 0.0402\n",
            "Epoch [6/100], Loss: 0.0450\n",
            "Epoch [7/100], Loss: 0.0392\n",
            "Epoch [8/100], Loss: 0.0425\n",
            "Epoch [9/100], Loss: 0.0374\n",
            "Epoch [10/100], Loss: 0.0374\n",
            "Epoch [11/100], Loss: 0.0389\n",
            "Epoch [12/100], Loss: 0.0340\n",
            "Epoch [13/100], Loss: 0.0328\n",
            "Epoch [14/100], Loss: 0.0385\n",
            "Epoch [15/100], Loss: 0.0388\n",
            "Epoch [16/100], Loss: 0.0402\n",
            "Epoch [17/100], Loss: 0.0339\n",
            "Epoch [18/100], Loss: 0.0389\n",
            "Epoch [19/100], Loss: 0.0364\n",
            "Epoch [20/100], Loss: 0.0370\n",
            "Epoch [21/100], Loss: 0.0379\n",
            "Epoch [22/100], Loss: 0.0406\n",
            "Epoch [23/100], Loss: 0.0358\n",
            "Epoch [24/100], Loss: 0.0415\n",
            "Epoch [25/100], Loss: 0.0329\n",
            "Epoch [26/100], Loss: 0.0324\n",
            "Epoch [27/100], Loss: 0.0381\n",
            "Epoch [28/100], Loss: 0.0427\n",
            "Epoch [29/100], Loss: 0.0420\n",
            "Epoch [30/100], Loss: 0.0376\n",
            "Epoch [31/100], Loss: 0.0352\n",
            "Epoch [32/100], Loss: 0.0350\n",
            "Epoch [33/100], Loss: 0.0375\n",
            "Epoch [34/100], Loss: 0.0352\n",
            "Epoch [35/100], Loss: 0.0324\n",
            "Epoch [36/100], Loss: 0.0319\n",
            "Epoch [37/100], Loss: 0.0383\n",
            "Epoch [38/100], Loss: 0.0388\n",
            "Epoch [39/100], Loss: 0.0363\n",
            "Epoch [40/100], Loss: 0.0337\n",
            "Epoch [41/100], Loss: 0.0376\n",
            "Epoch [42/100], Loss: 0.0373\n",
            "Epoch [43/100], Loss: 0.0350\n",
            "Epoch [44/100], Loss: 0.0339\n",
            "Epoch [45/100], Loss: 0.0355\n",
            "Epoch [46/100], Loss: 0.0353\n",
            "Epoch [47/100], Loss: 0.0381\n",
            "Epoch [48/100], Loss: 0.0398\n",
            "Epoch [49/100], Loss: 0.0374\n",
            "Epoch [50/100], Loss: 0.0404\n",
            "Epoch [51/100], Loss: 0.0374\n",
            "Epoch [52/100], Loss: 0.0331\n",
            "Epoch [53/100], Loss: 0.0327\n",
            "Epoch [54/100], Loss: 0.0373\n",
            "Epoch [55/100], Loss: 0.0374\n",
            "Epoch [56/100], Loss: 0.0358\n",
            "Epoch [57/100], Loss: 0.0373\n",
            "Epoch [58/100], Loss: 0.0368\n",
            "Epoch [59/100], Loss: 0.0360\n",
            "Epoch [60/100], Loss: 0.0363\n",
            "Epoch [61/100], Loss: 0.0324\n",
            "Epoch [62/100], Loss: 0.0376\n",
            "Epoch [63/100], Loss: 0.0330\n",
            "Epoch [64/100], Loss: 0.0300\n",
            "Epoch [65/100], Loss: 0.0378\n",
            "Epoch [66/100], Loss: 0.0389\n",
            "Epoch [67/100], Loss: 0.0367\n",
            "Epoch [68/100], Loss: 0.0431\n",
            "Epoch [69/100], Loss: 0.0340\n",
            "Epoch [70/100], Loss: 0.0328\n",
            "Epoch [71/100], Loss: 0.0375\n",
            "Epoch [72/100], Loss: 0.0344\n",
            "Epoch [73/100], Loss: 0.0328\n",
            "Epoch [74/100], Loss: 0.0329\n",
            "Epoch [75/100], Loss: 0.0362\n",
            "Epoch [76/100], Loss: 0.0360\n",
            "Epoch [77/100], Loss: 0.0315\n",
            "Epoch [78/100], Loss: 0.0357\n",
            "Epoch [79/100], Loss: 0.0332\n",
            "Epoch [80/100], Loss: 0.0359\n",
            "Epoch [81/100], Loss: 0.0324\n",
            "Epoch [82/100], Loss: 0.0375\n",
            "Epoch [83/100], Loss: 0.0367\n",
            "Epoch [84/100], Loss: 0.0324\n",
            "Epoch [85/100], Loss: 0.0385\n",
            "Epoch [86/100], Loss: 0.0353\n",
            "Epoch [87/100], Loss: 0.0369\n",
            "Epoch [88/100], Loss: 0.0364\n",
            "Epoch [89/100], Loss: 0.0401\n",
            "Epoch [90/100], Loss: 0.0383\n",
            "Epoch [91/100], Loss: 0.0372\n",
            "Epoch [92/100], Loss: 0.0344\n",
            "Epoch [93/100], Loss: 0.0344\n",
            "Epoch [94/100], Loss: 0.0424\n",
            "Epoch [95/100], Loss: 0.0340\n",
            "Epoch [96/100], Loss: 0.0415\n",
            "Epoch [97/100], Loss: 0.0390\n",
            "Epoch [98/100], Loss: 0.0406\n",
            "Epoch [99/100], Loss: 0.0335\n",
            "Epoch [100/100], Loss: 0.0306\n",
            "Predictions: [[0.5299804  0.52948564 0.5016906  0.5187947  0.5175398 ]\n",
            " [0.43756732 0.38864303 0.44598234 0.40522143 0.38964638]\n",
            " [0.46621764 0.47425303 0.5165456  0.4318689  0.44640216]\n",
            " [0.41212738 0.37689066 0.4021064  0.461388   0.4573171 ]\n",
            " [0.47936362 0.4507625  0.52408636 0.5220116  0.4980242 ]]\n",
            "Actual Values: [[[0.36831483]\n",
            "  [0.45235708]\n",
            "  [0.34459102]\n",
            "  [0.49491525]\n",
            "  [0.33697814]]\n",
            "\n",
            " [[0.5683901 ]\n",
            "  [0.551956  ]\n",
            "  [0.706383  ]\n",
            "  [0.55108356]\n",
            "  [0.5576102 ]]\n",
            "\n",
            " [[0.74148196]\n",
            "  [0.57596654]\n",
            "  [0.7268519 ]\n",
            "  [0.8041872 ]\n",
            "  [0.6678487 ]]\n",
            "\n",
            " [[0.26417804]\n",
            "  [0.17687075]\n",
            "  [0.1       ]\n",
            "  [0.253866  ]\n",
            "  [0.59375   ]]\n",
            "\n",
            " [[0.63868314]\n",
            "  [0.79744816]\n",
            "  [0.81565654]\n",
            "  [0.84671533]\n",
            "  [0.60674953]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4XJjnp0m078a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}